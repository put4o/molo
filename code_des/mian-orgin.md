ğŸ“‹ æ–‡æ¡£ RAG ä»»åŠ¡å®Œæ•´æµç¨‹ä¼ªä»£ç 
æ¦‚è¿°
è¿™æ˜¯ä¸€ä¸ªåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„æ–‡æ¡£æ£€ç´¢ç³»ç»Ÿï¼Œä½¿ç”¨ ColPali è¿›è¡Œå‘é‡ç´¢å¼•ï¼Œç»“åˆ Qwen-3B è¿›è¡Œé€»è¾‘æ„ŸçŸ¥çš„é¡µé¢æ£€ç´¢ã€‚

ç¬¬ä¸€é˜¶æ®µï¼šç´¢å¼• (Indexing)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç´¢å¼•é˜¶æ®µæµç¨‹                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åŠ è½½é…ç½®å‚æ•° â†’ åˆå§‹åŒ–ColPaliæ¨¡å‹ â†’ æ‰«æPDFæ–‡ä»¶åˆ—è¡¨          â”‚
â”‚        â†“                                                    â”‚
â”‚  éå†æ¯ä¸ªPDFæ–‡æ¡£ â”€â”€â†’ [å·²å­˜åœ¨åµŒå…¥?] â”€æ˜¯â†’ è·³è¿‡                 â”‚
â”‚        â†“ å¦                                                 â”‚
â”‚  PDFè½¬å›¾ç‰‡(144 DPI) â†’ åˆ†æ‰¹ç¼–ç  â†’ å­˜å‚¨åµŒå…¥å‘é‡                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
# ============================================================
# é˜¶æ®µä¸€ï¼šç´¢å¼•æ„å»º - PDFæ–‡æ¡£å‘é‡åŒ–
# å…¥å£å‘½ä»¤: python3 index.py --dataset MMLong --save_img
# ============================================================

PROCEDURE index_documents(dataset_name="MMLong"):
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æ­¥éª¤ 1: è§£æå‘½ä»¤è¡Œå‚æ•°å¹¶åˆå§‹åŒ–ç¯å¢ƒ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    SET save_dir       = "/gz-data/tmp/tmp_embs/{dataset_name}"      # åµŒå…¥ä¿å­˜è·¯å¾„
    SET img_save_dir   = "/gz-data/tmp/tmp_imgs/{dataset_name}"      # å›¾ç‰‡ä¿å­˜è·¯å¾„
    SET batch_size     = 32                                          # ç¼–ç æ‰¹å¤§å°
    SET model_name     = "vidore/colpali"                            # é¢„è®­ç»ƒæ¨¡å‹åç§°
    SET device         = "cuda:0"                                    # è®¡ç®—è®¾å¤‡
    SET resolution     = 144                                         # PDFè½¬å›¾ç‰‡åˆ†è¾¨ç‡(DPI)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æ­¥éª¤ 2: åˆå§‹åŒ– ColPali æ¨¡å‹å’Œå¤„ç†å™¨
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    # ColPali = ColQwen2 + PaliGemma çš„è§†è§‰è¯­è¨€æ¨¡å‹
    # ç”¨äºå°†å›¾åƒç¼–ç ä¸ºé«˜ç»´å‘é‡è¡¨ç¤º
    
    model = ColPali.from_pretrained(
        model_name,                           # åŠ è½½é¢„è®­ç»ƒæƒé‡
        torch_dtype=torch.bfloat16,           # ä½¿ç”¨bfloat16èŠ‚çœæ˜¾å­˜
        device_map=device                     # åˆ†é…åˆ°GPUè®¾å¤‡
    )
    model.eval()                              # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼(ä¸æ›´æ–°æ¢¯åº¦)
    
    processor = ColPaliProcessor.from_pretrained(model_name)
    # å¤„ç†å™¨è´Ÿè´£:
    #   - å°†PILå›¾åƒé¢„å¤„ç†ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
    #   - å°†æ–‡æœ¬æŸ¥è¯¢ç¼–ç ä¸ºå‘é‡
    #   - è®¡ç®—å¤šå‘é‡ç›¸ä¼¼åº¦åˆ†æ•°
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æ­¥éª¤ 3: æ‰«ææ•°æ®é›†ç›®å½•ï¼Œè·å–æ‰€æœ‰PDFæ–‡ä»¶åˆ—è¡¨
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    pdf_dir = "/gz-data/dataset/{dataset_name}"
    pdf_files = prepare_files(pdf_dir, suffix=".pdf")
    # prepare_files() å®ç°:
    #   RETURN [file for file in os.listdir(pdf_dir) if file.endswith(".pdf")]
    
    CREATE_DIR_IF_NOT_EXISTS(save_dir)
    CREATE_DIR_IF_NOT_EXISTS(img_save_dir)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æ­¥éª¤ 4: éå†æ¯ä¸ªPDFæ–‡æ¡£ï¼Œç”Ÿæˆå‘é‡åŒ–åµŒå…¥
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    FOR each pdf_file IN tqdm(pdf_files, desc="Encoding PDFs..."):
        
        doc_id = pdf_file.replace(".pdf", "")           # æå–æ–‡æ¡£ID (ä¸å«æ‰©å±•å)
        doc_path = "{pdf_dir}/{pdf_file}"               # å®Œæ•´PDFè·¯å¾„
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åµŒå…¥ï¼Œé¿å…é‡å¤è®¡ç®—
        IF os.path.exists("{save_dir}/{doc_id}.pt"):
            PRINT "Embeddings for {pdf_file} already exists. Skipping..."
            CONTINUE
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # å­æ­¥éª¤ 4.1: å°†PDFè½¬æ¢ä¸ºé¡µé¢å¿«ç…§å›¾åƒ
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        # ä½¿ç”¨ pdf2image åº“å°†PDFçš„æ¯ä¸€é¡µè½¬æ¢ä¸ºPNGå›¾åƒ
        page_images = convert_from_path(
            doc_path, 
            dpi=resolution                              # è®¾ç½®åˆ†è¾¨ç‡144 DPI
        )
        # convert_from_path() å®ç°:
        #   RETURN [PIL.Image.Image, ...]  # æ¯ä¸€é¡µçš„å›¾åƒåˆ—è¡¨
        
        # å¦‚æœæŒ‡å®šäº† --save_img å‚æ•°ï¼Œä¿å­˜å›¾åƒç”¨äºåç»­VLMåˆ†æ
        IF save_img_flag:
            FOR page_num, page_snapshot IN ENUMERATE(page_images):
                img_filename = "{doc_id}-{page_num+1}.png"   # é¡µç ä»1å¼€å§‹
                IF NOT os.path.exists("{img_save_dir}/{img_filename}"):
                    page_snapshot.save("{img_save_dir}/{img_filename}")
                    # ä¿å­˜ä¸ºPNGæ ¼å¼ï¼Œä¿ç•™é«˜è´¨é‡å›¾åƒç”¨äºVLMå¤„ç†
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # å­æ­¥éª¤ 4.2: åˆ†æ‰¹å°†å›¾åƒç¼–ç ä¸ºå‘é‡åµŒå…¥
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        total_image_embeds = torch.Tensor().to(device)   # åˆå§‹åŒ–ç©ºå¼ é‡å­˜å‚¨åµŒå…¥
        
        FOR idx IN RANGE(0, len(page_images), batch_size):
            
            # 4.2.1: è·å–å½“å‰æ‰¹æ¬¡çš„å›¾åƒ
            batch_images = page_images[idx : idx + batch_size]
            
            # 4.2.2: ä½¿ç”¨å¤„ç†å™¨é¢„å¤„ç†å›¾åƒ
            # - è°ƒæ•´å›¾åƒå¤§å°è‡³æ¨¡å‹è¦æ±‚çš„åˆ†è¾¨ç‡
            # - å½’ä¸€åŒ–åƒç´ å€¼
            # - è½¬æ¢ä¸ºPyTorchå¼ é‡
            batch_input = processor.process_images(batch_images)
            batch_input = batch_input.to(device)
            
            # 4.2.3: æ¸…ç†GPUæ˜¾å­˜ç¼“å­˜
            WITH torch.cuda.device(device):
                torch.cuda.empty_cache()
            
            # 4.2.4: å‰å‘ä¼ æ’­ç”Ÿæˆå›¾åƒåµŒå…¥
            WITH torch.no_grad():                           # å…³é—­æ¢¯åº¦è®¡ç®—
                image_embeds = model(**batch_input)
                # è¾“å‡ºå½¢çŠ¶: [batch_size, hidden_dim, seq_len]
                # ColPaliä½¿ç”¨å¤šå‘é‡è¾“å‡ºè¡¨ç¤ºå›¾åƒçš„ä¸åŒåŒºåŸŸ
            
            # 4.2.5: æ‹¼æ¥å½“å‰æ‰¹æ¬¡çš„åµŒå…¥åˆ°æ€»åµŒå…¥
            total_image_embeds = torch.cat(
                (total_image_embeds, image_embeds), 
                dim=0                                        # æŒ‰æ‰¹æ¬¡ç»´åº¦æ‹¼æ¥
            )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # å­æ­¥éª¤ 4.3: ä¿å­˜æ–‡æ¡£åµŒå…¥åˆ°ç£ç›˜
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        embed_path = "{save_dir}/{doc_id}.pt"
        torch.save(total_image_embeds, embed_path)
        PRINT "Save Embeddings {total_image_embeds.shape} to {embed_path}"
        
        # åµŒå…¥å¼ é‡å½¢çŠ¶è¯´æ˜:
        # [num_pages, hidden_dim, patch_seq_len]
        # ä¾‹å¦‚: [50, 128, 64] è¡¨ç¤º50é¡µæ–‡æ¡£, 128ç»´ç‰¹å¾, 64ä¸ªå›¾åƒå—
    
    PRINT "Indexing Complete!"
    
END PROCEDURE


ç¬¬äºŒé˜¶æ®µï¼šæ£€ç´¢ (Retrieving)
æµç¨‹å›¾
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ£€ç´¢é˜¶æ®µæµç¨‹                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  åŠ è½½æ–‡æ¡£åµŒå…¥ â†’ æ„å»ºé¡µé¢å›¾(beamsearch) â†’ åŠ è½½Qwen-3Bæ¨¡å‹                â”‚
â”‚        â†“                                                             â”‚
â”‚  éå†æ¯ä¸ªæŸ¥è¯¢æ ·æœ¬                                                      â”‚
â”‚        â†“                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Baseæ–¹æ³•:                                                        â”‚ â”‚
â”‚  â”‚   è®¡ç®—æŸ¥è¯¢å‘é‡ â†’ ä¸æ‰€æœ‰é¡µé¢è®¡ç®—ç›¸ä¼¼åº¦ â†’ è¿”å›Top-Ké¡µé¢               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Beamsearchæ–¹æ³• (VLMå¢å¼º):                                        â”‚ â”‚
â”‚  â”‚   åˆå§‹Beamé€‰æ‹© â†’ VLMè¯„ä¼°ç›¸å…³æ€§ â†’ é¡µé¢å›¾æ‰©å±• â†’ è¿­ä»£æœç´¢              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â†“                                                             â”‚
â”‚  ä¿å­˜æ£€ç´¢ç»“æœåˆ°JSONæ–‡ä»¶                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
# ============================================================
# é˜¶æ®µäºŒï¼šæ£€ç´¢ - é€»è¾‘æ„ŸçŸ¥çš„é¡µé¢æ£€ç´¢
# å…¥å£å‘½ä»¤: python3 retrieve.py --dataset MMLong --method beamsearch
# ============================================================

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å…¨å±€é…ç½®å‚æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ARGUMENTS:
    dataset     = "MMLong"                    # æ•°æ®é›†åç§°
    method      = "beamsearch"                # æ£€ç´¢æ–¹æ³•: "base" æˆ– "beamsearch"
    encoder     = "vidore/colpali"            # ç¼–ç å™¨æ¨¡å‹
    emb_root    = "/gz-data/tmp/tmp_embs"     # åµŒå…¥æ–‡ä»¶æ ¹ç›®å½•
    top_k       = 20                          # Baseæ–¹æ³•è¿”å›çš„Top-Kç»“æœ
    threshold   = 0.3                         # ç›¸ä¼¼åº¦é˜ˆå€¼(ç”¨äºbeamsearch)
    alpha       = 0.4                         # ç›¸ä¼¼åº¦æƒé‡: alpha*sim + (1-alpha)*vlm
    beam_width  = 3                           # Beamsearchå®½åº¦
    max_hop     = 4                           # æœ€å¤§æœç´¢è·³æ•°
    model_name  = "QwenVL-3B-lora"            # VLMæ¨¡å‹åç§°

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¾…åŠ©å‡½æ•°å®šä¹‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

FUNCTION query_vlm_relevance(query, doc_info, vlm_model):
    """
    ä½¿ç”¨Qwen-3B VLMè¯„ä¼°å•ä¸ªé¡µé¢ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§
    
    å‚æ•°:
        query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
        doc_info: å…ƒç»„ (doc_id, page_num)
        vlm_model: å·²åŠ è½½çš„Qwen-VLæ¨¡å‹
    
    è¿”å›:
        relevance_score: 1-5çš„æ•´æ•°ï¼Œè¡¨ç¤ºé¡µé¢ç›¸å…³æ€§
    """
    
    doc_id, page_num = doc_info
    
    # æ­¥éª¤1: ç¡®ä¿é¡µé¢å›¾åƒå­˜åœ¨
    img_path = "/gz-data/tmp/tmp_imgs/{args.dataset}/{doc_id}-{page_num}.png"
    IF NOT os.path.exists(img_path):
        # å¦‚æœå›¾åƒä¸å­˜åœ¨ï¼Œä»PDFé‡æ–°æå–è¯¥é¡µ
        page_image = convert_from_path(
            pdf_path="/gz-data/dataset/{args.dataset}/{doc_id}.pdf",
            first_page=page_num,
            last_page=page_num,
            dpi=144
        )[0]
        page_image.save(img_path, "PNG")
    
    # æ­¥éª¤2: ç”Ÿæˆç›¸å…³æ€§è¯„ä¼°æç¤ºè¯
    IF args.dataset == "MMLong":
        prompt = generate_relevance_prompt(query)
    ELSE:
        prompt = generate_relevance_prompt_detailed(query)
    
    # promptå†…å®¹ç¤ºä¾‹:
    # """
    # # GOAL #
    # You are a Retrieval Expert, evaluate page relevance to query.
    # Rate 1-5:
    # - 5: Highly relevant - contains complete information
    # - 4: Very relevant - contains most information  
    # - 3: Moderately relevant - contains some useful information
    # - 2: Slightly relevant - minor connection
    # - 1: Irrelevant - no related information
    # # QUERY #
    # {query}
    # Provide just a single number (1-5).
    # """
    
    # æ­¥éª¤3: è°ƒç”¨Qwen-VLæ¨¡å‹è¿›è¡Œæ¨ç†
    response = get_response_concat(
        vlm_model,
        prompt,
        img_path,
        max_new_tokens=16,          # åªéœ€è¦è¿”å›å•ä¸ªæ•°å­—
        temperature=1.0
    )
    # get_response_concat() å®ç°:
    #   1. æ„å»ºæ¶ˆæ¯: [ç”¨æˆ·è§’è‰², åŒ…å«å›¾åƒURLå’Œæ–‡æœ¬æç¤º]
    #   2. åº”ç”¨èŠå¤©æ¨¡æ¿
    #   3. å¤„ç†è§†è§‰ä¿¡æ¯
    #   4. æ¨¡å‹ç”Ÿæˆå“åº”
    #   5. è§£ç å¹¶æ¸…ç†ç‰¹æ®Štoken
    
    # æ­¥éª¤4: è§£æå“åº”æå–åˆ†æ•°
    score_match = REGEX_SEARCH(r'[1-5]', response)   # æå–ç¬¬ä¸€ä¸ª1-5çš„æ•°å­—
    IF score_match:
        relevance_score = INT(score_match.group(0))
    ELSE:
        relevance_score = 3                         # é»˜è®¤ä¸­ç­‰ç›¸å…³
    
    RETURN relevance_score


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ–‡æ¡£æ£€ç´¢å™¨ç±»å®šä¹‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CLASS DocumentRetriever:
    """
    ç»Ÿä¸€æ–‡æ¡£æ£€ç´¢ç±»ï¼Œæ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥
    """
    
    CONSTRUCTOR(encoder, processor, device, batch_size=512):
        self.encoder   = encoder          # ColPaliç¼–ç å™¨
        self.processor = processor        # å¤„ç†å™¨
        self.device    = device           # è®¡ç®—è®¾å¤‡
        self.batch_size = batch_size      # æ‰¹å¤„ç†å¤§å°
    
    FUNCTION compute_scores(query, all_embeds):
        """
        è®¡ç®—æŸ¥è¯¢ä¸æ‰€æœ‰é¡µé¢çš„ç›¸ä¼¼åº¦åˆ†æ•°
        """
        
        # æ­¥éª¤1: å°†æŸ¥è¯¢æ–‡æœ¬ç¼–ç ä¸ºå‘é‡
        queries = processor.process_queries(queries=[query])
        queries = queries.to(device)
        query_embeds = encoder(**queries)
        # query_embedså½¢çŠ¶: [1, hidden_dim, query_seq_len]
        
        # æ­¥éª¤2: åˆ†æ‰¹è®¡ç®—ä¸æ‰€æœ‰é¡µé¢çš„å¤šå‘é‡ç›¸ä¼¼åº¦
        all_scores = []
        
        FOR idx IN RANGE(0, all_embeds.shape[0], self.batch_size):
            
            batch_embeds = all_embeds[idx : idx + self.batch_size]
            batch_embeds = FloatTensor(batch_embeds).to(
                device=device,
                dtype=query_embeds.dtype
            )
            
            WITH torch.no_grad():
                # å¤šå‘é‡ç›¸ä¼¼åº¦è®¡ç®— (ColPaliç‰¹æœ‰)
                # å¯¹queryçš„æ¯ä¸ªå‘é‡ä¸pageçš„æ¯ä¸ªå‘é‡è®¡ç®—ç‚¹ç§¯
                tmp_scores = processor.score_multi_vector(
                    query_embeds,      # [1, hidden_dim, q_seq]
                    batch_embeds       # [batch, hidden_dim, p_seq]
                )
                # è¾“å‡ºå½¢çŠ¶: [batch_size, query_seq, page_seq]
                # éœ€è¦æ ¹æ®å½¢çŠ¶è¿›è¡Œå¤„ç†
                IF len(tmp_scores.shape) > 1:
                    tmp_scores = tmp_scores[0]   # å–ç¬¬ä¸€ä¸ªç»´åº¦
            
            all_scores.append(tmp_scores)
        
        # æ­¥éª¤3: åˆå¹¶æ‰€æœ‰åˆ†æ•°
        scores = torch.cat(all_scores, dim=0).cpu()
        
        # æ¸…ç†å†…å­˜
        DEL all_scores, queries, query_embeds
        
        RETURN scores
    
    FUNCTION base_retrieve(query, all_embeds, top_k=10):
        """
        åŸºç¡€æ£€ç´¢æ–¹æ³•ï¼šç›´æ¥åŸºäºå‘é‡ç›¸ä¼¼åº¦
        """
        
        # è®¡ç®—æ‰€æœ‰é¡µé¢çš„ç›¸ä¼¼åº¦åˆ†æ•°
        scores = compute_scores(query, all_embeds)
        
        # æ’åºå¹¶è¿”å›Top-Kç»“æœ
        top_indices = scores.argsort(dim=-1, descending=True)[:top_k]
        top_scores = scores[top_indices].tolist()
        
        # é¡µç ä»1å¼€å§‹è®¡æ•°
        RETURN [idx + 1 FOR idx IN top_indices], top_scores
    
    FUNCTION vlm_retrieve(query, all_embeds, graph, doc_id, 
                         beam_width=3, max_hop=5, verbose=True):
        """
        VLMå¢å¼ºçš„Beamsearchæ£€ç´¢æ–¹æ³•
        
        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            all_embeds: æ–‡æ¡£æ‰€æœ‰é¡µé¢çš„åµŒå…¥å‘é‡
            graph: é¡µé¢é‚»æ¥å›¾ {page_idx: [neighbor_idx, ...]}
            doc_id: æ–‡æ¡£ID
            beam_width: æ¯è½®ä¿ç•™çš„å€™é€‰æ•°é‡
            max_hop: æœ€å¤§æœç´¢è·³æ•°
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        
        # æ­¥éª¤1: è®¡ç®—åˆå§‹ç›¸ä¼¼åº¦åˆ†æ•°
        scores = compute_scores(query, all_embeds)
        
        # æ­¥éª¤2: å½’ä¸€åŒ–åˆ†æ•°åˆ°[0, 1]èŒƒå›´
        min_score = torch.min(scores).item()
        max_score = torch.max(scores).item()
        score_range = max_score - min_score IF max_score > min_score ELSE 1.0
        
        score_dict = {
            i: (scores[i].item() - min_score) / score_range 
            FOR i IN RANGE(scores.shape[0])
        }
        
        # æ­¥éª¤3: åˆå§‹åŒ–Beam
        # é€‰æ‹©ç›¸ä¼¼åº¦æœ€é«˜çš„beam_widthä¸ªé¡µé¢ä½œä¸ºåˆå§‹å€™é€‰
        initial_beam = scores.argsort(dim=-1, descending=True)[:beam_width]
        initial_beam = initial_beam.tolist()
        
        visited = SET(initial_beam)              # è®°å½•å·²è®¿é—®çš„é¡µé¢
        vlm_score_cache = {}                     # ç¼“å­˜VLMè¯„ä¼°ç»“æœ
        vlm_query_times = 0                      # VLMè°ƒç”¨æ¬¡æ•°è®¡æ•°
        
        # æ­¥éª¤4: è¯„ä¼°åˆå§‹Beamä¸­æ¯ä¸ªé¡µé¢çš„VLMç›¸å…³æ€§
        FOR node IN initial_beam:
            
            # è°ƒç”¨Qwen-VLè¯„ä¼°é¡µé¢ç›¸å…³æ€§
            vlm_score = query_vlm_relevance(
                query, 
                (doc_id, node + 1),     # é¡µç ä»1å¼€å§‹
                vlm_model
            )
            
            vlm_query_times += 1
            vlm_score_cache[node] = vlm_score
            
            # å½’ä¸€åŒ–VLMåˆ†æ•°åˆ°[0, 1]
            norm_vlm_score = (vlm_score - 1.0) / 4.0
            
            # ç»¼åˆåˆ†æ•° = alpha * ç›¸ä¼¼åº¦ + (1-alpha) * VLMåˆ†æ•°
            combined_score = args.alpha * score_dict[node] + \
                            (1.0 - args.alpha) * norm_vlm_score
            score_dict[node] = combined_score
        
        IF verbose:
            PRINT f"Initial Beam: {[n+1 FOR n IN initial_beam]}"
            PRINT f"Initial Scores: {[round(score_dict[n], 3) FOR n IN initial_beam]}"
        
        # è®°å½•å½“å‰æœ€ä¼˜ç»“æœ
        result_dict = {node: score_dict[node] FOR node IN initial_beam}
        
        # æ­¥éª¤5: å¼€å§‹Beamsearchè¿­ä»£
        FOR hop IN RANGE(max_hop):
            
            candidates = []        # å€™é€‰é‚»å±…é¡µé¢
            
            FOR node IN current_beam:
                # è·å–å½“å‰èŠ‚ç‚¹çš„é‚»å±…é¡µé¢
                neighbor_pages = graph.get(node, [])
                
                FOR neighbor IN neighbor_pages:
                    IF neighbor NOT IN visited:
                        
                        # æ ‡è®°ä¸ºå·²è®¿é—®
                        visited.add(neighbor)
                        
                        # VLMè¯„ä¼°é‚»å±…é¡µé¢
                        vlm_score = query_vlm_relevance(
                            query,
                            (doc_id, neighbor + 1),
                            vlm_model
                        )
                        vlm_query_times += 1
                        vlm_score_cache[neighbor] = vlm_score
                        
                        norm_vlm_score = (vlm_score - 1.0) / 4.0
                        
                        # è®¡ç®—ç»¼åˆåˆ†æ•°
                        combined_score = args.alpha * score_dict[neighbor] + \
                                        (1.0 - args.alpha) * norm_vlm_score
                        score_dict[neighbor] = combined_score
                        
                        candidates.append((neighbor, combined_score))
                        result_dict[neighbor] = combined_score
            
            # å¦‚æœæ²¡æœ‰æ–°å€™é€‰ï¼Œé€€å‡ºæœç´¢
            IF NOT candidates:
                BREAK
            
            # æ­¥éª¤6: é€‰æ‹©Top-Kå€™é€‰ä½œä¸ºä¸‹ä¸€è½®Beam
            candidates = SORTED(candidates, key=lambda x: x[1], reverse=True)[:beam_width]
            current_beam = [node FOR node, _ IN candidates]
            
            IF verbose:
                PRINT f"Hop {hop+1}: Beam = {[n+1 FOR n IN current_beam]}"
                PRINT f"Hop {hop+1}: Scores = {[round(score_dict[n], 3) FOR n IN current_beam]}"
        
        # æ­¥éª¤7: è¿‡æ»¤å’Œæ’åºæœ€ç»ˆç»“æœ
        final_results = [
            (node, score) FOR node, score IN result_dict.items()
            IF score >= threshold
        ]
        final_results = SORTED(final_results, key=lambda x: x[1], reverse=True)
        
        # æå–é¡µé¢ç¼–å·å’Œåˆ†æ•°
        evidence_pages = [node + 1 FOR node, _ IN final_results]
        page_scores = [score FOR _, score IN final_results]
        
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        
        PRINT f"Total Pages: {all_embeds.shape[0]}"
        PRINT f"VLM Query Times: {vlm_query_times}"
        
        RETURN evidence_pages, page_scores


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä¸»ç¨‹åºå…¥å£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PROCEDURE main_retrieval():
    
    # æ­¥éª¤1: åˆå§‹åŒ–è®¾å¤‡
    device = torch.device("cuda:0")
    
    # æ­¥éª¤2: åŠ è½½æ‰€æœ‰æ–‡æ¡£çš„åµŒå…¥å‘é‡
    emb_root = "/gz-data/tmp/tmp_embs/{dataset}"
    doc2emb = load_all_doc_embeddings(emb_root)
    # load_all_doc_embeddings() å®ç°:
    #   FOR each .pt file IN emb_root:
    #       embeds = torch.load(file, map_location="cpu")
    #       doc_id = filename.replace(".pt", "")
    #       doc2emb[doc_id] = embeds.detach().numpy()
    #   RETURN doc2emb  # {doc_id: numpy_array}
    
    # æ­¥éª¤3: åˆå§‹åŒ–ColPaliç¼–ç å™¨
    encoder = ColPali.from_pretrained(
        encoder_model,
        torch_dtype=torch.bfloat16,
        device_map=device
    ).eval()
    
    processor = ColPaliProcessor.from_pretrained(encoder_model)
    retriever = DocumentRetriever(
        encoder=encoder,
        processor=processor,
        device=device
    )
    
    # æ­¥éª¤4: åŠ è½½æŸ¥è¯¢æ ·æœ¬
    samples = json.load(open("/gz-data/dataset/samples_{dataset}.json", "r"))
    # samplesç»“æ„:
    # [
    #   {
    #     "question": "...",
    #     "doc_id": "xxx.pdf",
    #     "evidence_pages": [5, 12, 23],  # å¯é€‰çš„ground truth
    #     ...
    #   },
    #   ...
    # ]
    
    # æ­¥éª¤5: å¦‚æœä½¿ç”¨beamsearchæ–¹æ³•ï¼Œé¢å¤–åˆå§‹åŒ–
    IF method == "beamsearch":
        
        # 5.1: åŠ è½½Qwen-3B VLMæ¨¡å‹
        vlm_model = init_model(model_name, device)
        # init_model() å®ç°:
        #   model_path = "/gz-data/models"
        #   model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
        #       model_path,
        #       torch_dtype=torch.bfloat16,
        #       device_map=device
        #   ).eval()
        #   processor = AutoProcessor.from_pretrained(model_path)
        #   RETURN model
        
        # 5.2: æ„å»ºæ‰€æœ‰æ–‡æ¡£çš„é¡µé¢é‚»æ¥å›¾
        doc2graph = {}
        
        FOR doc_id, doc_emb IN tqdm(doc2emb.items(), desc="Constructing Page Graph"):
            
            graph = construct_page_graph(doc_emb, threshold=0.8, sim_measure="cosine")
            # construct_page_graph() å®ç°:
            #   n_pages = doc_emb.shape[0]
            #   IF n_pages <= 3: RETURN None
            #   
            #   # è®¡ç®—æ‰€æœ‰é¡µé¢ä¸¤ä¸¤ä¹‹é—´çš„ç›¸ä¼¼åº¦
            #   sim_matrix = np.zeros((n_pages, n_pages))
            #   FOR i IN range(n_pages):
            #       FOR j IN range(i+1, n_pages):
            #           vec_i = doc_emb[i]   # [hidden_dim, seq_len]
            #           vec_j = doc_emb[j]
            #           sim = compute_embed_similarity(vec_i, vec_j, "cosine")
            #           sim_matrix[i][j] = sim
            #           sim_matrix[j][i] = sim
            #   
            #   # æ„å»ºKNNå›¾ (æ¯ä¸ªèŠ‚ç‚¹è¿æ¥top-kç›¸ä¼¼é‚»å±…)
            #   page_graph = defaultdict(list)
            #   k_value = 5
            #   threshold = 0.8
            #   FOR i IN range(n_pages):
            #       top_k_idx = np.argsort(sim_matrix[i])[::-1][:k_value]
            #       FOR j IN top_k_idx:
            #           IF sim_matrix[i][j] >= threshold:
            #               page_graph[i].append(j)
            #               page_graph[j].append(i)
            #   
            #   RETURN page_graph  # {page_idx: [neighbor_idx, ...]}
            
            doc2graph[doc_id] = deepcopy(graph)
    
    # æ­¥éª¤6: éå†æ¯ä¸ªæŸ¥è¯¢æ ·æœ¬è¿›è¡Œæ£€ç´¢
    FOR sample IN tqdm(samples, desc="Retrieving"):
        
        query = sample["question"]
        target_doc = sample["doc_id"].replace(".pdf", "")
        target_doc_embedding = doc2emb[target_doc]
        
        IF method == "base":
            # åŸºç¡€æ£€ç´¢ï¼šçº¯å‘é‡ç›¸ä¼¼åº¦
            ranked_pages, page_scores = retriever.base_retrieve(
                query,
                target_doc_embedding,
                top_k=top_k
            )
            
        ELIF method == "beamsearch":
            # VLMå¢å¼ºæ£€ç´¢ï¼šç»“åˆå‘é‡ç›¸ä¼¼åº¦å’Œè¯­ä¹‰ç†è§£
            target_graph = doc2graph.get(target_doc, defaultdict(list))
            
            ranked_pages, page_scores = retriever.vlm_retrieve(
                query,
                target_doc_embedding,
                target_graph,
                target_doc,
                beam_width=beam_width,
                max_hop=max_hop,
                verbose=beam_verbose
            )
        
        # æ­¥éª¤7: ä¿å­˜æ£€ç´¢ç»“æœ
        sample["pages_ranking"] = str(ranked_pages)
        sample["pages_scores"] = str(page_scores)
        
        IF "evidence_pages" IN sample:
            PRINT f"Ground-truth: {sample['evidence_pages']}")
        
        PRINT f"Prediction: {ranked_pages[:5]}")
        
        # å®æ—¶ä¿å­˜åˆ°JSONæ–‡ä»¶
        output_file = "/gz-data/dataset/retrieved/samples_{dataset}_{method}{vlm_suffix}.json"
        CREATE_DIR_IF_NOT_EXISTS(os.path.dirname(output_file))
        json.dump(samples, open(output_file, "w"), indent=4)
    
    PRINT "Retrieval Complete!"

END PROCEDURE

æµç¨‹æ€»ç»“å›¾
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          MoLoRAG å®Œæ•´æµç¨‹                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚  Step 1: Indexing  â”‚         â”‚ Step 2: Retrieving â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚            â”‚                              â”‚                                  â”‚
â”‚            â–¼                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ PDF Documents      â”‚         â”‚ User Query         â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚            â”‚                              â”‚                                  â”‚
â”‚            â–¼                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ pdf2image          â”‚         â”‚ ColPali Encoder    â”‚                      â”‚
â”‚  â”‚ (144 DPI)          â”‚         â”‚ Query â†’ Vector     â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚            â”‚                              â”‚                                  â”‚
â”‚            â–¼                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ ColPali Model      â”‚         â”‚ Similarity Search  â”‚                      â”‚
â”‚  â”‚ Image â†’ Embeddings â”‚         â”‚ Base Method        â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚            â”‚                                                               â”‚
â”‚            â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚ Save to .pt Files  â”‚                                                    â”‚
â”‚  â”‚ [pages, dim, seq]  â”‚                                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚                                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                             â”‚
â”‚                              Beamsearch æµç¨‹                                 â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ Page Graph         â”‚    â”‚ Qwen-3B VLM        â”‚                          â”‚
â”‚  â”‚ (KNN, cos>0.8)     â”‚    â”‚ Relevance Scoring  â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚            â”‚                              â”‚                                  â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                       â–¼                                                     â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚            â”‚ Beam Search Loop   â”‚                                            â”‚
â”‚            â”‚ 1. Select Top-K    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚            â”‚ 2. VLM Evaluation  â”‚                  â”‚                         â”‚
â”‚            â”‚ 3. Graph Expansion â”‚                  â”‚                         â”‚
â”‚            â”‚ 4. Re-rank         â”‚                  â”‚                         â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚                         â”‚
â”‚                       â”‚                             â”‚                         â”‚
â”‚                       â–¼                             â”‚                         â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚                         â”‚
â”‚            â”‚ Evidence Pages     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚            â”‚ + Scores           â”‚        (until max_hop)                      â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



ğŸ”‘ å…³é”®ç»„ä»¶è¯´æ˜
ç»„ä»¶	ä½œç”¨	å…³é”®æŠ€æœ¯
ColPali	å¤šæ¨¡æ€æ–‡æ¡£åµŒå…¥æ¨¡å‹	åŸºäºPaliGemmaï¼Œå°†å›¾åƒè½¬æ¢ä¸ºé«˜ç»´å‘é‡
ColPaliProcessor	é¢„å¤„ç†/åå¤„ç†	å›¾åƒå¤„ç†ã€æŸ¥è¯¢ç¼–ç ã€å¤šå‘é‡ç›¸ä¼¼åº¦è®¡ç®—
Qwen-3B	è§†è§‰è¯­è¨€æ¨¡å‹	ç†è§£æ–‡æ¡£é¡µé¢å†…å®¹ï¼Œè¯„ä¼°ç›¸å…³æ€§(1-5åˆ†)
Page Graph	é¡µé¢é‚»æ¥å›¾	åŸºäºç›¸ä¼¼åº¦çš„KNNå›¾ï¼Œæ”¯æŒBeamsearchæ‰©å±•
Multi-vector Similarity	å¤šå‘é‡åŒ¹é…	å¤„ç†æ–‡æ¡£ä¸­çš„å¤šåŒºåŸŸã€å¤šå—å†…å®¹åŒ¹é…